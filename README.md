# ğŸ’³ Real-Time Banking Data Pipeline
End-to-End Streaming â€¢ Warehouse â€¢ Orchestration â€¢ Analytics

This project is a real-time banking data engineering pipeline built using a modern data stack. It mirrors how enterprise financial systems process high-volume transactional data reliably and securely.

Unlike typical tutorial projects using clean Kaggle datasets, this pipeline handles:
âœ” Real-time CDC streaming
âœ” Raw JSON ingestion
âœ” Data quality issues
âœ” Multi-layer modeling (Bronze, Silver, Gold)
âœ” SCD Type 2 dimensions
âœ” Automated orchestration
âœ” CI/CD deployment
âœ” Live dashboards

This is designed to reflect real-world banking systems.

# ğŸ“Œ Architecture Overview

<img width="2816" height="1536" alt="Gemini_Generated_Image_9mhhxf9mhhxf9mhh" src="https://github.com/user-attachments/assets/bf33e469-ca24-49cc-a86a-691aee635269" />


## ğŸ¦ 1. Data Source & OLTP Layer (PostgreSQL)

The pipeline starts with a PostgreSQL OLTP database, simulating core banking tables:

ğŸ‘¥ customers

ğŸ’¼ accounts

ğŸ’¸ transactions

Because banking systems cannot expose APIs publicly, generator code simulates secure transactional activity.

Why SQL here?

ACID transactions

Strong consistency

Structured schema suitable for financial logic

## âš¡ 2. Real-Time Streaming with Kafka + Debezium (CDC)

To capture changes in real time, the project uses:

ğŸŸ¦ Kafka for distributed streaming

ğŸŸ© Debezium for Change Data Capture

Debezium listens to PostgreSQL logs and streams:

inserts

updates

deletes

Raw data is streamed out as JSON strings for downstream processing.

## ğŸª£ 3. Object Storage (S3 / MinIO)

Kafka consumer writes the streaming data into an S3-compatible store:

Parquet files for efficient storage

Separate folders for each table

Acts as a durable landing zone

## ğŸ” 4. Orchestration with Apache Airflow

Airflow automates the ETL and transformation workloads:

DAG pulls raw data from S3

Loads into Snowflake Bronze layer

Triggers DBT transformations

Runs SCD2 snapshots

Fully scheduled daily/real-time runs

## â„ï¸ 5. Data Warehouse (Snowflake)

The warehouse follows the Medallion Architecture:

ğŸ¥‰ Bronze

Raw JSON in a single VARIANT column

Simplifies ingestion

ğŸ¥ˆ Silver

Cleaned and typed tables

Deduped CDC events

ğŸ¥‡ Gold

Business-ready star schema

SCD2 applied to dimension tables

Fact tables prepared for analytics

## ğŸ›  6. DBT for Transformations & SCD Type 2

DBT handles all SQL transformations:

Staging models

Snapshot-based SCD2

Surrogate keys

Tests for quality

Environment-based deployments

ğŸ“˜ SCD Type 2 Logic

Tracks historical changes such as updated emails or account types:

Old record â†’ is_current = false

New record â†’ inserted with is_current = true

Full history preserved

## ğŸš€ 7. CI/CD & DevOps Integration

This project includes enterprise deployment workflows:

ğŸ³ Docker

Containers for PostgreSQL, Kafka, Debezium, Airflow, MinIO

ğŸ” Secrets

Managed using .env + GitHub Secrets

No credentials inside repository

ğŸ¤– GitHub Actions

CI: DBT compile, syntax checks

CD: Deploy DBT models/snapshots automatically

## ğŸ“Š 8. Power BI Analytics Dashboard

Power BI connects to Snowflake using DirectQuery, enabling:

Real-time metrics

No manual refresh

Direct visibility into Gold models

Dashboard Includes:

Total customers

Account balances

Transaction trends

Top customers by activity

Fraud-like behavior patterns


# ğŸ§  Skills Covered
Data Engineering

Kafka streaming

Debezium CDC

Snowflake warehousing

DBT modeling

Airflow orchestration

Real-time ETL/ELT pipelines

Data Modeling

Star schema design

SCD Type 2

Fact/dimension modeling

DevOps

Docker

CI/CD with GitHub Actions

Secrets management

Programming

Python

SQL

Jinja/DBT

Business Intelligence

Power BI dashboards

DirectQuery for real-time insights

# ğŸ“ Contact

If you want to collaborate or discuss data engineering projects, feel free to reach out:

ğŸ‘¤ Lakshmi Prasad Bathina
ğŸ”— LinkedIn: https://www.linkedin.com/in/lakshmi-prasad-b-91a67b198/

ğŸ“§ Email: blaxmiprasad6@gmail.com
